{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0485b31-9e59-4ab9-bfaf-289ea822fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "%config InlineBackend.figure_gformat = \"retina\"\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "SEED_VALUE = 0\n",
    "os.environ[\"PYHTONSEED\"] = str(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "torch.manual_seed(SEED_VALUE)\n",
    "\n",
    "alpha = 1\n",
    "start_N = 30\n",
    "worst_N = 500\n",
    "training_iter = 1000\n",
    "target = \"measured log solubility in mols per litre\"\n",
    "target_value = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30624ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime :  06/18/21:00\n",
      "06182100\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "def timestamp():\n",
    "    time_cur = datetime.datetime.now()\n",
    "    print(\"datetime : \", time_cur.strftime(\"%m/%d/%H:%M\"))\n",
    "    stamp = time_cur.strftime(\"%m%d%H%M\")\n",
    "    return stamp\n",
    "\n",
    "stamp = timestamp()\n",
    "print(stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e9eadd-d551-4023-b2e9-51358cc6954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(y, x):\n",
    "    \n",
    "    \"\"\"\n",
    "    input\n",
    "    y:(2n)\n",
    "    x:(2n, n)\n",
    "    \n",
    "    output\n",
    "    grad:(n)\n",
    "    \"\"\"\n",
    "    grad_list = []\n",
    "    \n",
    "    for i in range(x.shape[1]):\n",
    "        grad = (y[2*i] - y[2*i+1])/(x[2*i, i] - x[2*i+1, i])\n",
    "        grad_list.append(grad)\n",
    "        \n",
    "    assert x.shape[1] == torch.tensor(grad_list).shape[0], f'{x.shape[1]}→{torch.tensor(grad_list).shape[0]}'\n",
    "        \n",
    "    return torch.tensor(grad_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631124d4-d1f0-42ae-901d-44ff28868dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_grad(x, delta=1e-3):\n",
    "    \n",
    "    \"\"\"\n",
    "    input\n",
    "    (n,)\n",
    "    \n",
    "    output\n",
    "    (2n, n)\n",
    "    \"\"\"\n",
    "    \n",
    "    x_for_grad_list = []\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        tmp = torch.vstack((x, x))\n",
    "        tmp[0,i] += delta\n",
    "        tmp[1:,i] -= delta\n",
    "        x_for_grad_list.append(tmp)\n",
    "        \n",
    "    prepare_for_grad_x = torch.cat(x_for_grad_list, dim=0)\n",
    "        \n",
    "    assert x.shape[0]*2 == prepare_for_grad_x.shape[0], f'{x.shape[0]*2}→{prepare_for_grad_x.shape[0]}'\n",
    "    \n",
    "    return prepare_for_grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e9c5e6d-629b-4edb-acae-c2565423713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_IG(model, x, N=100, sampling=100):\n",
    "    \"\"\"\n",
    "    model:学習済みGP\n",
    "    x:解釈したいデータ(tensor)\n",
    "    N:IGを計算する際の分割数\n",
    "    sampling:GPからサンプリングする数\n",
    "    return:\n",
    "    \"\"\"\n",
    "    for s in range(sampling):\n",
    "        \n",
    "        #経路微分に必要なデータを作成する\n",
    "        for n in range(N+1):\n",
    "            x_n = x * n/N\n",
    "            x_n_for_grad = prepare_for_grad(x_n)\n",
    "            \n",
    "            if n == 0:\n",
    "                all_x_n_for_grad = x_n_for_grad.detach().clone()\n",
    "            else:\n",
    "                all_x_n_for_grad = torch.vstack((all_x_n_for_grad, x_n_for_grad))\n",
    "                \n",
    "        assert all_x_n_for_grad.numpy().shape == (x.shape[0]*2*(N+1) , x.shape[0]), print(f\"{all_x_n_for_grad.numpy().shape}→{(x.shape[0]*2*(N+1) , x.shape[0])}\")\n",
    "        \n",
    "        #yをサンプリングする\n",
    "        all_y_sampling_for_grad = model(all_x_n_for_grad).sample()\n",
    "        \n",
    "        #各経路での勾配を計算する\n",
    "        for n2 in range(N+1):\n",
    "            \n",
    "            y_sampling_for_grad = all_y_sampling_for_grad[n2*x.shape[0]*2:((n2+1)*x.shape[0]*2)]\n",
    "            x_n_for_grad = all_x_n_for_grad[n2*x.shape[0]*2:((n2+1)*x.shape[0]*2),:]\n",
    "\n",
    "            #勾配を計算する\n",
    "            grad = calc_grad(y_sampling_for_grad, x_n_for_grad)\n",
    "            \n",
    "            if n2 == 0:\n",
    "                all_grad = grad.detach().clone()\n",
    "            else:\n",
    "                all_grad = torch.vstack((all_grad, grad))\n",
    "\n",
    "        IG = all_grad.mean(axis=0)\n",
    "        \n",
    "        if s == 0:\n",
    "            all_IG = IG.detach().clone()\n",
    "        else:\n",
    "            all_IG = torch.vstack((all_IG, IG))\n",
    "        \n",
    "    assert all_IG.numpy().shape == (sampling, x.shape[0]), print(f\"{all_IG.numpy().shape }→{(sampling, x.shape[0])}\")\n",
    "    \n",
    "    return all_IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc071de-3352-4041-a6b9-8736e50208de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [21:00:01] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "[21:00:01] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem,Draw, Descriptors, Descriptors3D\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from IPython.display import SVG\n",
    "\n",
    "def draw_mol_ig_with_2c(mol, bits_ig, alpha=2, color=0.5):\n",
    "    \n",
    "    bits = [int(k) for k in bits_ig.keys()]\n",
    "    value_max = [v.mean(axis=0) + alpha * v.std(axis=0, ddof=0) for v in bits_ig.values()]\n",
    "    value_min = [v.mean(axis=0) - alpha * v.std(axis=0, ddof=0) for v in bits_ig.values()]\n",
    "    \n",
    "    bits_ig_max = dict(zip(bits, value_max))\n",
    "    bits_ig_min = dict(zip(bits, value_min))\n",
    "    \n",
    "    #フィンガープリントを計算\n",
    "    bitI_morgan = {}\n",
    "    fp_morgan = AllChem.GetMorganFingerprint(mol, 2, bitInfo=bitI_morgan)\n",
    "\n",
    "    #寄与のあるビットの抜き出し\n",
    "    bit_list = list(set(bits_ig_max.keys())&set(bitI_morgan.keys()))\n",
    "    \n",
    "    #寄与を格納する配列を生成\n",
    "    Ai_max_list = np.zeros(mol.GetNumAtoms())\n",
    "    Ai_min_list = np.zeros(mol.GetNumAtoms())\n",
    "\n",
    "    for bit in bit_list:\n",
    "\n",
    "        #フィンガープリントの寄与\n",
    "        Cn_max = bits_ig_max[int(bit)]\n",
    "        Cn_min = bits_ig_min[int(bit)]\n",
    "\n",
    "        #分子中に含まれる部分構造の数\n",
    "        fn = len(bitI_morgan[bit])\n",
    "\n",
    "        for part in bitI_morgan[bit]:\n",
    "            #fingerprintのradiusが0の時はfingerprintの中心原子を抜き出し、寄与を加算する。\n",
    "            if part[1]==0:\n",
    "                i = part[0]\n",
    "                xn = 1\n",
    "                #Ai_max_list[i] += Cn_max /  xn\n",
    "                #Ai_min_list[i] += Cn_min /  xn\n",
    "                \n",
    "                Ai_max_list[i] += Cn_max / fn / xn\n",
    "                Ai_min_list[i] += Cn_min / fn / xn\n",
    "                #Ai_list[i] += Cn\n",
    "                \n",
    "\n",
    "            #fingerprintのradiouが0以上の時は、該当する原子のリストを抜き出し、寄与を加算する\n",
    "            else:\n",
    "                amap={}\n",
    "                env = Chem.FindAtomEnvironmentOfRadiusN(mol,\n",
    "                                                        radius=part[1],\n",
    "                                                        rootedAtAtom=part[0])\n",
    "                submol=Chem.PathToSubmol(mol,env,atomMap=amap)\n",
    "\n",
    "                #各部分構造に含まれる原子数\n",
    "                xn = len(list(amap.keys()))\n",
    "\n",
    "                for i in amap.keys():\n",
    "                    #Ai_max_list[i] += Cn_max /  xn\n",
    "                    #Ai_min_list[i] += Cn_min /  xn\n",
    "                    \n",
    "                    Ai_max_list[i] += Cn_max / fn / xn\n",
    "                    Ai_min_list[i] += Cn_min / fn / xn\n",
    "                    #Ai_list[i] += Cn\n",
    "\n",
    "    #正規化っぽいことをする\n",
    "    #絶対値の最大値が0.5になるように調整する\n",
    "    scale_value = max(abs(Ai_max_list).max(), abs(Ai_min_list).max())\n",
    "    Ai_max_list = (Ai_max_list / scale_value) *0.5\n",
    "    Ai_min_list = (Ai_min_list / scale_value) *0.5\n",
    "    \n",
    "    # ハイライトする原子と色，円の半径を設定\n",
    "    atoms = [i for i in range(len(Ai_max_list))]\n",
    "    atom_colors = dict()\n",
    "    raddi_high_lights = dict()\n",
    "    for i in atoms:\n",
    "        raddi_high_lights[i] = color\n",
    "        if Ai_max_list[i] > 0:\n",
    "            if Ai_min_list[i] > 0:\n",
    "                atom_colors[i] = [(1,1-Ai_max_list[i],1-Ai_max_list[i]), (1,1-Ai_min_list[i],1-Ai_min_list[i])]\n",
    "            else:\n",
    "                atom_colors[i] = [(1,1-Ai_max_list[i],1-Ai_max_list[i]), (1+Ai_min_list[i],1+Ai_min_list[i],1)]\n",
    "        elif Ai_max_list[i] < 0:\n",
    "            if Ai_min_list[i] > 0:\n",
    "                atom_colors[i] = [(1+Ai_max_list[i],1+Ai_max_list[i],1), (1,1-Ai_max_list[i],1-Ai_min_list[i])]\n",
    "            else:\n",
    "                atom_colors[i] = [(1+Ai_max_list[i],1+Ai_max_list[i],1), (1+Ai_min_list[i],1+Ai_min_list[i],1)]\n",
    "        \n",
    "                \n",
    "\n",
    "    # コンテナの準備\n",
    "    view = rdMolDraw2D.MolDraw2DSVG(300,350)\n",
    "    tm = rdMolDraw2D.PrepareMolForDrawing(mol)\n",
    "    \n",
    "    # 分子をコンテナに登録\n",
    "    view.DrawMoleculeWithHighlights(tm, \n",
    "                                   '',\n",
    "                                   dict(atom_colors),\n",
    "                                   dict() ,\n",
    "                                   raddi_high_lights,\n",
    "                                   {})\n",
    "\n",
    "    \n",
    "    #ファイナライズ、保存、描画\n",
    "    view.FinishDrawing()\n",
    "    svg = view.GetDrawingText()\n",
    "\n",
    "    return SVG(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_known = pd.read_csv(\"data/start_data.csv\", index_col=0)\n",
    "print(df_known.shape)\n",
    "df_known.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4533fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = [int(i) for i in df_known.iloc[:,1:].columns.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66505b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smiles = pd.read_csv(\"data/delaney-processed.csv\", index_col=0)\n",
    "df = pd.read_csv(\"data/all_data.csv\", index_col=0)\n",
    "df_unknown = df.drop(df_known.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fbcbb76-8f5c-465e-8037-0efbddf124a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6d791f8-0a4a-4a76-b561-2eb62be84c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=1, max=-3.22\n",
      "mean:-4.830, std:1.488\n",
      "trans-1,4-Dimethylcyclohexane measured value: -4.470\n",
      "i=2, max=-3.22\n",
      "mean:-4.771, std:1.462\n",
      "2-Methyltetrahydrofurane measured value: 0.110\n",
      "i=3, max=0.11\n",
      "mean:-4.071, std:1.630\n",
      "1,2-Propylene oxide measured value: -0.590\n",
      "i=4, max=0.11\n",
      "mean:-3.961, std:1.636\n",
      "Tetrahydrofurane  measured value: 0.490\n",
      "i=5, max=0.49\n",
      "mean:-3.666, std:1.662\n",
      "Tetrahydropyran  measured value: -0.030\n",
      "i=6, max=0.49\n",
      "mean:-4.294, std:1.669\n",
      "Cyclopentene  measured value: -2.100\n",
      "i=7, max=0.49\n",
      "mean:-3.908, std:1.429\n",
      "Ethylene measured value: -0.400\n",
      "i=8, max=0.49\n",
      "mean:-3.437, std:1.515\n",
      "Methane measured value: -0.900\n",
      "i=9, max=0.49\n",
      "mean:-3.645, std:1.628\n",
      "Ethyne measured value: 0.290\n",
      "i=10, max=0.49\n",
      "mean:-3.717, std:1.730\n",
      "Acrylonitrile measured value: 0.150\n",
      "i=11, max=0.49\n",
      "mean:-2.843, std:1.706\n",
      "1,3-Butadiene measured value: -1.870\n",
      "i=12, max=0.49\n",
      "mean:-3.202, std:1.719\n",
      "Acrolein measured value: 0.570\n",
      "i=13, max=0.57\n",
      "mean:-2.613, std:1.766\n",
      "t-Crotonaldehyde measured value: 0.320\n",
      "i=14, max=0.57\n",
      "mean:-2.167, std:1.742\n",
      "2-butenal measured value: 0.320\n",
      "i=15, max=0.57\n",
      "mean:-2.503, std:1.672\n",
      "Propylene measured value: -1.080\n",
      "i=16, max=0.57\n",
      "mean:-2.775, std:1.803\n",
      "allicin measured value: -0.830\n",
      "i=17, max=0.57\n",
      "mean:-2.835, std:1.764\n",
      "Methyl formate measured value: 0.580\n",
      "i=18, max=0.58\n",
      "mean:-2.327, std:1.654\n",
      "Nitromethane measured value: 0.260\n",
      "i=19, max=0.58\n",
      "mean:-2.187, std:1.666\n",
      "Methyl acrylate measured value: -0.220\n",
      "i=20, max=0.58\n",
      "mean:-2.134, std:1.416\n",
      "Chloroethylene measured value: -1.750\n",
      "i=21, max=0.58\n",
      "mean:-2.344, std:1.610\n",
      "Ethyl formate measured value: 0.150\n",
      "i=22, max=0.58\n",
      "mean:-2.003, std:1.462\n",
      "Propionaldehyde measured value: 0.580\n",
      "i=23, max=0.58\n",
      "mean:-1.814, std:1.451\n",
      "Nitroethane measured value: -0.220\n",
      "i=24, max=0.58\n",
      "mean:-2.031, std:1.568\n",
      "Acetamide measured value: 1.580\n",
      "CPU times: user 5d 8h 41min 8s, sys: 3h 56min 22s, total: 5d 12h 37min 31s\n",
      "Wall time: 10h 8min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import joblib\n",
    "\n",
    "max_list = []\n",
    "value_list = []\n",
    "iter_number = 0\n",
    "\n",
    "while max(df_known[target]) < target_value:\n",
    "    \n",
    "    df_0 = df_known.copy()\n",
    "    \n",
    "    iter_number += 1\n",
    "    print(f\"i={iter_number}, max={max(df_known[target])}\")\n",
    "    max_list.append(max(df_known[target]))\n",
    "    \n",
    "    y_known_tensor = torch.from_numpy(df_0.iloc[:,0].values.astype(np.float32))\n",
    "    x_known_tensor = torch.from_numpy(df_0.iloc[:,1:].values.astype(np.float32))\n",
    "    x_unknown_tensor = torch.from_numpy(df_unknown.iloc[:,1:].values.astype(np.float32))\n",
    "\n",
    "    x_mean_tensor = x_known_tensor.mean(axis=0)\n",
    "    x_std_tensor = x_known_tensor.std(axis=0)\n",
    "    y_mean_tensor = y_known_tensor.mean(axis=0)\n",
    "    y_std_tensor = y_known_tensor.std(axis=0)\n",
    "\n",
    "    autoscaled_x_known_tensor = (x_known_tensor - x_mean_tensor)/x_std_tensor\n",
    "    autoscaled_x_unknown_tensor = (x_unknown_tensor - x_mean_tensor)/x_std_tensor\n",
    "    autoscaled_y_known_tensor = (y_known_tensor - y_mean_tensor)/y_std_tensor\n",
    "    \n",
    "    \n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(autoscaled_x_known_tensor, autoscaled_y_known_tensor, likelihood)\n",
    "    \n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1) \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=3, min_lr=1e-4)\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    \n",
    "    for _ in range(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(autoscaled_x_known_tensor)\n",
    "        loss = -mll(output, autoscaled_y_known_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        autoscaled_y_pred = likelihood(model(x_unknown_tensor))\n",
    "        y_pred = autoscaled_y_pred.mean * y_std_tensor + y_mean_tensor\n",
    "        y_std = (autoscaled_y_pred.variance ** 0.5) * y_std_tensor\n",
    "        UCB = y_pred + alpha * y_std\n",
    "    \n",
    "    next_sample_number = torch.where(UCB == max(UCB))[0][0].item()   \n",
    "    next_sample = df_unknown.iloc[[next_sample_number],:]\n",
    "    print(f\"mean:{y_pred[next_sample_number]:.3f}, std:{y_std[next_sample_number]:.3f}\")\n",
    "    print(f\"{next_sample.index[0]} measured value: {df.loc[next_sample.index,target][0]:.3f}\")\n",
    "    value_list.append(df.loc[next_sample.index,target][0])\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(df_smiles.loc[next_sample.index[0],\"smiles\"])\n",
    "    gp_ig = GP_IG(model, autoscaled_x_unknown_tensor[next_sample_number,:], sampling=500) * autoscaled_x_unknown_tensor[next_sample_number,:]\n",
    "    bits_ig = dict(zip(bits, gp_ig.numpy().T))\n",
    "    \n",
    "    save_dic = {}\n",
    "    \n",
    "    save_dic[\"iter_number\"] = iter_number\n",
    "    save_dic[\"x\"] = autoscaled_x_unknown_tensor[next_sample_number]\n",
    "    save_dic[\"index\"] = next_sample.index[0]\n",
    "    save_dic[\"target\"] = df.loc[next_sample.index,target][0]\n",
    "    save_dic[\"GP_IG\"] = gp_ig\n",
    "    save_dic[\"y_pred_mean\"] = y_pred[next_sample_number]\n",
    "    save_dic[\"y_pred_std\"] = y_std[next_sample_number]\n",
    "    \n",
    "    joblib.dump(save_dic, f'{results_path}/interpret_results_{iter_number}_{next_sample.index[0]}_{stamp}.pkl')\n",
    "    \n",
    "    \n",
    "    #display(draw_mol_ig_with_2c(mol, bits_ig, alpha=alpha))\n",
    "    \n",
    "    df_unknown.drop(next_sample.index.to_list(), axis=0, inplace=True)\n",
    "    df_known = pd.concat([df_known, next_sample], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6db7b2b5-927e-4cca-8193-334b390f32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_known.to_csv(f\"{results_path}/finish_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9e87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fe8d5be4002adedc4236d54e4f1bb08f0fc045825f3cdcbe245065332003bc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
