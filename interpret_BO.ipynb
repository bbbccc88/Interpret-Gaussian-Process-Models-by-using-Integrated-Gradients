{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0485b31-9e59-4ab9-bfaf-289ea822fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "%config InlineBackend.figure_gformat = \"retina\"\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "SEED_VALUE = 0\n",
    "os.environ[\"PYHTONSEED\"] = str(SEED_VALUE)\n",
    "random.seed(SEED_VALUE)\n",
    "np.random.seed(SEED_VALUE)\n",
    "torch.manual_seed(SEED_VALUE)\n",
    "\n",
    "alpha = 1\n",
    "start_N = 30\n",
    "worst_N = 500\n",
    "training_iter = 1000\n",
    "target = \"measured log solubility in mols per litre\"\n",
    "target_value = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30624ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime :  2408/01/22:2859\n",
      "240801222859\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "def timestamp():\n",
    "    time_cur = datetime.datetime.now()\n",
    "    print(\"datetime : \", time_cur.strftime(\"%y%m/%d/%H:%M%S\"))\n",
    "    stamp = time_cur.strftime(\"%y%m%d%H%M%S\")\n",
    "    return stamp\n",
    "\n",
    "stamp = timestamp()\n",
    "print(stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e9eadd-d551-4023-b2e9-51358cc6954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(y, x):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        y : target variables (2n,)\n",
    "        x : input varibales (2n, n)\n",
    "\n",
    "    Return:\n",
    "        grad : (n)\n",
    "    \"\"\"\n",
    "    grad_list = []\n",
    "    \n",
    "    for i in range(x.shape[1]):\n",
    "        grad = (y[2*i] - y[2*i+1])/(x[2*i, i] - x[2*i+1, i])\n",
    "        grad_list.append(grad)\n",
    "        \n",
    "    assert x.shape[1] == torch.tensor(grad_list).shape[0], f'{x.shape[1]}→{torch.tensor(grad_list).shape[0]}'\n",
    "        \n",
    "    return torch.tensor(grad_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631124d4-d1f0-42ae-901d-44ff28868dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_grad(x, delta=1e-3):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : input(n,)\n",
    "        delta : small amount\n",
    "        \n",
    "    Return:\n",
    "        prepare_for_grad_x) : data for calculate grads (2n, n)\n",
    "    \"\"\"\n",
    "    \n",
    "    x_for_grad_list = []\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        tmp = torch.vstack((x, x))\n",
    "        tmp[0,i] += delta\n",
    "        tmp[1,i] -= delta\n",
    "        x_for_grad_list.append(tmp)\n",
    "        \n",
    "    prepare_for_grad_x = torch.cat(x_for_grad_list, dim=0)\n",
    "        \n",
    "    assert x.shape[0]*2 == prepare_for_grad_x.shape[0], f'{x.shape[0]*2}→{prepare_for_grad_x.shape[0]}'\n",
    "    \n",
    "    return prepare_for_grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e9c5e6d-629b-4edb-acae-c2565423713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GP_IG(model, x, N=100, sampling=100):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model : trained gaussian process model\n",
    "        x : input varibales (n)\n",
    "        N : the number of steps for calculate integrated gradients\n",
    "        samping : the number of functions sampled from model\n",
    "\n",
    "    Return:\n",
    "        all_IG : calculated all integrated gradients\n",
    "    \"\"\"\n",
    "    \n",
    "    for s in range(sampling):\n",
    "        \n",
    "        for n in range(N+1):\n",
    "            x_n = x * n/N\n",
    "            x_n_for_grad = prepare_for_grad(x_n)\n",
    "            \n",
    "            if n == 0:\n",
    "                all_x_n_for_grad = x_n_for_grad.detach().clone()\n",
    "            else:\n",
    "                all_x_n_for_grad = torch.vstack((all_x_n_for_grad, x_n_for_grad))\n",
    "                \n",
    "        assert all_x_n_for_grad.cpu().numpy().shape == (x.shape[0]*2*(N+1) , x.shape[0]), f\"{all_x_n_for_grad.numpy().shape}→{(x.shape[0]*2*(N+1) , x.shape[0])}\"\n",
    "        \n",
    "        all_y_sampling_for_grad = model(all_x_n_for_grad).sample()\n",
    "        \n",
    "        for n2 in range(N+1):\n",
    "            \n",
    "            y_sampling_for_grad = all_y_sampling_for_grad[n2*x.shape[0]*2:((n2+1)*x.shape[0]*2)]\n",
    "            x_n_for_grad = all_x_n_for_grad[n2*x.shape[0]*2:((n2+1)*x.shape[0]*2),:]\n",
    "\n",
    "            grad = calc_grad(y_sampling_for_grad, x_n_for_grad).detach()\n",
    "            \n",
    "            if n2 == 0:\n",
    "                all_grad = grad.detach().clone()\n",
    "            else:\n",
    "                all_grad = torch.vstack((all_grad, grad))\n",
    "\n",
    "        IG = all_grad.mean(axis=0).detach()\n",
    "        \n",
    "        if s == 0:\n",
    "            all_IG = IG.detach().clone()\n",
    "        else:\n",
    "            all_IG = torch.vstack((all_IG, IG))\n",
    "        \n",
    "    assert all_IG.cpu().numpy().shape == (sampling, x.shape[0]), f\"{all_IG.numpy().shape }→{(sampling, x.shape[0])}\"\n",
    "    \n",
    "    return all_IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc071de-3352-4041-a6b9-8736e50208de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [22:28:59] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "[22:28:59] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem,Draw, Descriptors, Descriptors3D\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from IPython.display import SVG\n",
    "\n",
    "def draw_mol_ig_with_2c(mol, bits_ig, alpha=2, color=0.5):\n",
    "    \n",
    "    bits = [int(k) for k in bits_ig.keys()]\n",
    "    value_max = [v.mean(axis=0) + alpha * v.std(axis=0, ddof=0) for v in bits_ig.values()]\n",
    "    value_min = [v.mean(axis=0) - alpha * v.std(axis=0, ddof=0) for v in bits_ig.values()]\n",
    "    \n",
    "    bits_ig_max = dict(zip(bits, value_max))\n",
    "    bits_ig_min = dict(zip(bits, value_min))\n",
    "    \n",
    "    bitI_morgan = {}\n",
    "    fp_morgan = AllChem.GetMorganFingerprint(mol, 2, bitInfo=bitI_morgan)\n",
    "\n",
    "    bit_list = list(set(bits_ig_max.keys())&set(bitI_morgan.keys()))\n",
    "    \n",
    "    Ai_max_list = np.zeros(mol.GetNumAtoms())\n",
    "    Ai_min_list = np.zeros(mol.GetNumAtoms())\n",
    "\n",
    "    for bit in bit_list:\n",
    "\n",
    "        Cn_max = bits_ig_max[int(bit)]\n",
    "        Cn_min = bits_ig_min[int(bit)]\n",
    "\n",
    "        fn = len(bitI_morgan[bit])\n",
    "\n",
    "        for part in bitI_morgan[bit]:\n",
    "            if part[1]==0:\n",
    "                i = part[0]\n",
    "                xn = 1\n",
    "                \n",
    "                Ai_max_list[i] += Cn_max / fn / xn\n",
    "                Ai_min_list[i] += Cn_min / fn / xn\n",
    "                \n",
    "\n",
    "            else:\n",
    "                amap={}\n",
    "                env = Chem.FindAtomEnvironmentOfRadiusN(mol,\n",
    "                                                        radius=part[1],\n",
    "                                                        rootedAtAtom=part[0])\n",
    "                submol=Chem.PathToSubmol(mol,env,atomMap=amap)\n",
    "\n",
    "                xn = len(list(amap.keys()))\n",
    "\n",
    "                for i in amap.keys():\n",
    "                    \n",
    "                    Ai_max_list[i] += Cn_max / fn / xn\n",
    "                    Ai_min_list[i] += Cn_min / fn / xn\n",
    "            \n",
    "    scale_value = max(abs(Ai_max_list).max(), abs(Ai_min_list).max())\n",
    "    Ai_max_list = (Ai_max_list / scale_value) *0.5\n",
    "    Ai_min_list = (Ai_min_list / scale_value) *0.5\n",
    "    \n",
    "    atoms = [i for i in range(len(Ai_max_list))]\n",
    "    atom_colors = dict()\n",
    "    raddi_high_lights = dict()\n",
    "    for i in atoms:\n",
    "        raddi_high_lights[i] = color\n",
    "        if Ai_max_list[i] > 0:\n",
    "            if Ai_min_list[i] > 0:\n",
    "                atom_colors[i] = [(1,1-Ai_max_list[i],1-Ai_max_list[i]), (1,1-Ai_min_list[i],1-Ai_min_list[i])]\n",
    "            else:\n",
    "                atom_colors[i] = [(1,1-Ai_max_list[i],1-Ai_max_list[i]), (1+Ai_min_list[i],1+Ai_min_list[i],1)]\n",
    "        elif Ai_max_list[i] < 0:\n",
    "            if Ai_min_list[i] > 0:\n",
    "                atom_colors[i] = [(1+Ai_max_list[i],1+Ai_max_list[i],1), (1,1-Ai_max_list[i],1-Ai_min_list[i])]\n",
    "            else:\n",
    "                atom_colors[i] = [(1+Ai_max_list[i],1+Ai_max_list[i],1), (1+Ai_min_list[i],1+Ai_min_list[i],1)]\n",
    "        \n",
    "                \n",
    "\n",
    "    view = rdMolDraw2D.MolDraw2DSVG(300,350)\n",
    "    tm = rdMolDraw2D.PrepareMolForDrawing(mol)\n",
    "    \n",
    "    view.DrawMoleculeWithHighlights(tm, \n",
    "                                   '',\n",
    "                                   dict(atom_colors),\n",
    "                                   dict() ,\n",
    "                                   raddi_high_lights,\n",
    "                                   {})\n",
    "\n",
    "    \n",
    "    view.FinishDrawing()\n",
    "    svg = view.GetDrawingText()\n",
    "\n",
    "    return SVG(svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72976e-032c-479c-8f67-2d8aa0be0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_known = pd.read_csv(\"data/start_data.csv\", index_col=0)\n",
    "print(df_known.shape)\n",
    "df_known.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9800b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "bits = [int(i) for i in df_known.iloc[:,1:].columns.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046f04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_smiles = pd.read_csv(\"data/delaney-processed.csv\", index_col=0)\n",
    "df = pd.read_csv(\"data/all_data.csv\", index_col=0)\n",
    "df_unknown = df.drop(df_known.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fbcbb76-8f5c-465e-8037-0efbddf124a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ac39597",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = f'results/results_BO_alpha_{alpha}_{stamp}'\n",
    "os.makedirs(results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6d791f8-0a4a-4a76-b561-2eb62be84c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=1, max=-3.22\n",
      "outputscale: 0.515 lengthscale: 2.256   noise: 0.441\n",
      "mean:-4.103, std:1.286\n",
      "Methylcyclohexane  measured value: -3.850\n",
      "i=2, max=-3.22\n",
      "outputscale: 0.909 lengthscale: 2.027   noise: 0.044\n",
      "mean:-3.962, std:1.213\n",
      "Terbutryn measured value: -4.000\n",
      "i=3, max=-3.22\n",
      "outputscale: 0.906 lengthscale: 2.146   noise: 0.043\n",
      "mean:-4.091, std:1.253\n",
      "2,4-Dinitrotoluene measured value: -2.820\n",
      "i=4, max=-2.82\n",
      "outputscale: 0.905 lengthscale: 2.269   noise: 0.028\n",
      "mean:-3.881, std:1.142\n",
      "p-Nitrotoluene measured value: -2.490\n",
      "i=5, max=-2.49\n",
      "outputscale: 0.915 lengthscale: 2.670   noise: 0.025\n",
      "mean:-3.072, std:0.958\n",
      "o-Nitrotoluene measured value: -2.330\n",
      "i=6, max=-2.33\n",
      "outputscale: 0.904 lengthscale: 2.957   noise: 0.020\n",
      "mean:-3.200, std:1.131\n",
      "4-Chlorotoluene measured value: -3.080\n",
      "i=7, max=-2.33\n",
      "outputscale: 0.929 lengthscale: 3.328   noise: 0.018\n",
      "mean:-3.204, std:1.128\n",
      "1,2-Dinitrobenzene measured value: -3.100\n",
      "i=8, max=-2.33\n",
      "outputscale: 0.937 lengthscale: 3.537   noise: 0.017\n",
      "mean:-3.250, std:1.193\n",
      "2,6-Dinitrotoluene measured value: -3.000\n",
      "i=9, max=-2.33\n",
      "outputscale: 0.933 lengthscale: 3.671   noise: 0.016\n",
      "mean:-3.155, std:0.965\n",
      "o-Xylene  measured value: -2.800\n",
      "i=10, max=-2.33\n",
      "outputscale: 0.957 lengthscale: 3.875   noise: 0.013\n",
      "mean:-3.543, std:1.263\n",
      "2-Methylphenol measured value: -0.620\n",
      "i=11, max=-0.62\n",
      "outputscale: 1.064 lengthscale: 4.403   noise: 0.010\n",
      "mean:-1.107, std:0.626\n",
      "p-Cresol measured value: -0.730\n",
      "i=12, max=-0.62\n",
      "outputscale: 1.024 lengthscale: 4.630   noise: 0.007\n",
      "mean:-1.819, std:1.205\n",
      "1,2-Benzenediol measured value: 0.620\n",
      "i=13, max=0.62\n",
      "outputscale: 1.189 lengthscale: 5.547   noise: 0.006\n",
      "mean:0.391, std:0.466\n",
      "1,4-Benzenediol measured value: -0.170\n",
      "i=14, max=0.62\n",
      "outputscale: 0.970 lengthscale: 5.031   noise: 0.007\n",
      "mean:-1.190, std:0.909\n",
      "Guaiacol measured value: -1.960\n",
      "i=15, max=0.62\n",
      "outputscale: 0.925 lengthscale: 4.914   noise: 0.007\n",
      "mean:-0.979, std:0.449\n",
      "o-Nitrophenol measured value: -1.740\n",
      "i=16, max=0.62\n",
      "outputscale: 0.890 lengthscale: 4.765   noise: 0.009\n",
      "mean:-1.668, std:1.137\n",
      "1,3-Benzenediol measured value: 0.810\n",
      "i=17, max=0.81\n",
      "outputscale: 0.854 lengthscale: 4.597   noise: 0.009\n",
      "mean:-1.228, std:0.985\n",
      "2,6-Dimethylphenol measured value: -1.290\n",
      "i=18, max=0.81\n",
      "outputscale: 0.823 lengthscale: 4.555   noise: 0.009\n",
      "mean:-1.950, std:1.550\n",
      "methyl gallate measured value: -1.240\n",
      "i=19, max=0.81\n",
      "outputscale: 0.841 lengthscale: 4.530   noise: 0.010\n",
      "mean:-1.649, std:1.177\n",
      "5-hydroxyquinoline measured value: -2.540\n",
      "i=20, max=0.81\n",
      "outputscale: 0.805 lengthscale: 4.362   noise: 0.009\n",
      "mean:-1.020, std:0.531\n",
      "3-Methylphenol measured value: -0.680\n",
      "i=21, max=0.81\n",
      "outputscale: 0.742 lengthscale: 4.146   noise: 0.006\n",
      "mean:-1.803, std:1.015\n",
      "Phenol measured value: 0.000\n",
      "i=22, max=0.81\n",
      "outputscale: 0.758 lengthscale: 4.240   noise: 0.006\n",
      "mean:-0.940, std:0.974\n",
      "p-Phenylphenol measured value: -3.480\n",
      "i=23, max=0.81\n",
      "outputscale: 0.752 lengthscale: 3.815   noise: 0.006\n",
      "mean:-1.288, std:0.809\n",
      "4-hydroxypyridine measured value: 1.020\n",
      "CPU times: user 4d 2h 33min 54s, sys: 5h 18min 43s, total: 4d 7h 52min 37s\n",
      "Wall time: 6h 49min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import joblib\n",
    "\n",
    "max_list = []\n",
    "value_list = []\n",
    "iter_number = 0\n",
    "\n",
    "while max(df_known[target]) < target_value:\n",
    "    \n",
    "    df_0 = df_known.copy()\n",
    "    \n",
    "    iter_number += 1\n",
    "    print(f\"i={iter_number}, max={max(df_known[target])}\")\n",
    "    max_list.append(max(df_known[target]))\n",
    "    \n",
    "    y_known_tensor = torch.from_numpy(df_0.iloc[:,0].values.astype(np.float32))\n",
    "    x_known_tensor = torch.from_numpy(df_0.iloc[:,1:].values.astype(np.float32))\n",
    "    x_unknown_tensor = torch.from_numpy(df_unknown.iloc[:,1:].values.astype(np.float32))\n",
    "\n",
    "    x_mean_tensor = x_known_tensor.mean(axis=0)\n",
    "    x_std_tensor = x_known_tensor.std(axis=0)\n",
    "    y_mean_tensor = y_known_tensor.mean(axis=0)\n",
    "    y_std_tensor = y_known_tensor.std(axis=0)\n",
    "\n",
    "    autoscaled_x_known_tensor = (x_known_tensor - x_mean_tensor)/x_std_tensor\n",
    "    autoscaled_x_unknown_tensor = (x_unknown_tensor - x_mean_tensor)/x_std_tensor\n",
    "    autoscaled_y_known_tensor = (y_known_tensor - y_mean_tensor)/y_std_tensor\n",
    "    \n",
    "    \n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "    model = ExactGPModel(autoscaled_x_known_tensor, autoscaled_y_known_tensor, likelihood)\n",
    "    \n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.1) \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=3, min_lr=1e-4)\n",
    "\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "    \n",
    "    for _ in range(training_iter):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(autoscaled_x_known_tensor)\n",
    "        loss = -mll(output, autoscaled_y_known_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    \n",
    "    print('outputscale: %.3f lengthscale: %.3f   noise: %.3f' % (model.covar_module.outputscale.item(), \n",
    "                                                                 model.covar_module.base_kernel.lengthscale.item(),\n",
    "                                                                     model.likelihood.noise.item()))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        autoscaled_y_pred = likelihood(model(autoscaled_x_unknown_tensor))\n",
    "        y_pred = autoscaled_y_pred.mean * y_std_tensor + y_mean_tensor\n",
    "        y_std = autoscaled_y_pred.stddev * y_std_tensor\n",
    "        UCB = y_pred + alpha * y_std\n",
    "    \n",
    "    next_sample_number = torch.where(UCB == max(UCB))[0][0].item()   \n",
    "    next_sample = df_unknown.iloc[[next_sample_number],:]\n",
    "    print(f\"mean:{y_pred[next_sample_number]:.3f}, std:{y_std[next_sample_number]:.3f}\")\n",
    "    print(f\"{next_sample.index[0]} measured value: {df.loc[next_sample.index,target][0]:.3f}\")\n",
    "    value_list.append(df.loc[next_sample.index,target][0])\n",
    "    \n",
    "    mol = Chem.MolFromSmiles(df_smiles.loc[next_sample.index[0],\"smiles\"])\n",
    "    gp_ig = GP_IG(model, autoscaled_x_unknown_tensor[next_sample_number,:], sampling=10)\n",
    "    bits_ig = dict(zip(bits, gp_ig.numpy().T))\n",
    "    \n",
    "    save_dic = {}\n",
    "    \n",
    "    save_dic[\"iter_number\"] = iter_number\n",
    "    save_dic[\"x\"] = autoscaled_x_unknown_tensor[next_sample_number]\n",
    "    save_dic[\"index\"] = next_sample.index[0]\n",
    "    save_dic[\"target\"] = df.loc[next_sample.index,target][0]\n",
    "    save_dic[\"GP_IG\"] = gp_ig\n",
    "    save_dic[\"y_pred_mean\"] = y_pred[next_sample_number]\n",
    "    save_dic[\"y_pred_std\"] = y_std[next_sample_number]\n",
    "    \n",
    "    joblib.dump(save_dic, f'{results_path}/interpret_results_{iter_number}_{next_sample.index[0]}_{stamp}.pkl')\n",
    "    \n",
    "    \n",
    "    #display(draw_mol_ig_with_2c(mol, bits_ig, alpha=alpha))\n",
    "    \n",
    "    df_unknown.drop(next_sample.index.to_list(), axis=0, inplace=True)\n",
    "    df_known = pd.concat([df_known, next_sample], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ccaebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9046e1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fe8d5be4002adedc4236d54e4f1bb08f0fc045825f3cdcbe245065332003bc9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
